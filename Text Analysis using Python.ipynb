{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6208bae6",
   "metadata": {},
   "source": [
    "# Text Analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22466b85",
   "metadata": {},
   "source": [
    "Project Summary: Language Translation and Text Analysis\n",
    "\n",
    "The project focuses on developing a language translation and text analysis tool using Python. It encompasses several functions and components to perform various operations on textual data. Here is a summary of the key functionalities:\n",
    "\n",
    "1. Text Processing:\n",
    "   - The project includes functions to read text from files, remove punctuation, split text into sentences, and extract word lists from sentences.\n",
    "   - The `read_file` function reads the contents of a file and returns them as a string.\n",
    "   - The `remove_punc2` function removes punctuation characters from a given text, creating a clean version of the text.\n",
    "\n",
    "2. Language Translation:\n",
    "   - The translation functionality involves converting English words to their Latin counterparts.\n",
    "   - The `translate` function utilizes a rule-based approach to transform English words to Latin. It identifies the first vowel occurrence, moves consonants before it to the end, and appends the suffix 'ay'.\n",
    "\n",
    "3. Text Analysis:\n",
    "   - The project includes functions for analyzing and manipulating text data.\n",
    "   - The `split_sentences` function splits a text string into a list of sentences based on common sentence-ending markers like '.', '?', and '!'.\n",
    "   - The `starts_with_vowel` function checks if a given string starts with a vowel.\n",
    "   - The `following` function retrieves the list of users that a specific user is following in a social network, based on a list of follower-followee relationships.\n",
    "\n",
    "4. Social Network Analysis:\n",
    "   - The project incorporates functionalities related to social network analysis.\n",
    "   - The `list_textfiles` function returns a list of filenames ending in '.txt' in a specified directory.\n",
    "   - The code reads follower-followee relationships from a file and stores them in a dictionary data structure (`edge_dict`).\n",
    "   - The `following2` function utilizes the `edge_dict` to find the list of users a given user is following.\n",
    "\n",
    "5. Performance Evaluation:\n",
    "   - The project includes the use of the `%timeit` magic command to measure the execution time of specific functions.\n",
    "\n",
    "Overall, the project combines various components to offer language translation capabilities, text analysis functionalities, and social network analysis features. It provides users with tools to process text data, analyze relationships in social networks, and translate words from English to Latin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cd6785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/Users/yogeshgupta/Downloads/austen-emma-excerpt.txt' mode='r' encoding='UTF-8'>\n",
      "78\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Importing the data\n",
    "infile = open('/Users/yogeshgupta/Downloads/austen-emma-excerpt.txt')\n",
    "print(infile)\n",
    "text = infile.read()\n",
    "print(text.count(\"e\"))\n",
    "print(text.count('an'))\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a3e632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿ Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "78\n"
     ]
    }
   ],
   "source": [
    "# The code reads a text and counts the number of occurrences of the letter 'e' in the text. \n",
    "# It then prints the original text and the count of 'e' occurrences.\n",
    "nE = 0\n",
    "print(text)\n",
    "for x in text:\n",
    "    if 'e' in x:\n",
    "        nE = nE + x.count('e')\n",
    "\n",
    "print(nE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ee45b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(text.count(' an '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da92881b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "# This code counts the number of occurrences of the letter 'e' in the `text` string and stores the \n",
    "# count in the variable `counts`, then prints the count.\n",
    "counts = 0 \n",
    "item_to_count = text\n",
    "for txt in text:\n",
    "    if 'e' == txt:\n",
    "        counts = counts + 1\n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b86d1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `remove_punc2` function removes punctuation characters from the `text` string and returns the cleaned version.\n",
    "def remove_punc2(text):\n",
    "    punctuation = '!@#$%^&*()_-+={}[]:;\"\\'|<>>,.?/~`»¿'\n",
    "    clean_text = \"\"\n",
    "    for character in text:\n",
    "        if character not in punctuation:\n",
    "            clean_text += character\n",
    "    return clean_text\n",
    "\n",
    "#short_text = \"Commas, as it turns out, are overestimated. Dots, however, even more so!\"\n",
    "#words = remove_punc2(text)\n",
    "#count = {}\n",
    "#textSplit = words.split(' ')\n",
    "#for x in textSplit:\n",
    "#        if x in text:\n",
    "#            count[x] = count[x] + 1\n",
    "#        else:\n",
    "#            count[x] = 1\n",
    "        #print('The word '+ x +' occurred ' +str(wordCount))\n",
    "#print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c0a3f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'P')\n",
      "(1, 'y')\n",
      "(2, 't')\n",
      "(3, 'h')\n",
      "(4, 'o')\n",
      "(5, 'n')\n"
     ]
    }
   ],
   "source": [
    "for element in enumerate(\"Python\"):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "957a91a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for index, character in enumerate(\"Python\"):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "239bd4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿ Emma by Jane Austen 1816\n",
      "\n",
      "VOLUME I\n",
      "\n",
      "CHAPTER I\n",
      "\n",
      "\n",
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home\n",
      "and happy disposition, seemed to unite some of the best blessings\n",
      "of existence; and had lived nearly twenty-one years in the world\n",
      "with very little to distress or vex her.\n",
      "\n",
      "She was the youngest of the two daughters of a most affectionate,\n",
      "indulgent father; and had, in consequence of her sister's marriage,\n",
      "been mistress of his house from a very early period.  Her mother\n",
      "had died too long ago for her to have more than an indistinct\n",
      "remembrance of her caresses; and her place had been supplied\n",
      "by an excellent woman as governess, who had fallen little short\n",
      "of a mother in affection.\n",
      "\n",
      "/Users/yogeshgupta/Downloads/textanalysis/austen-emma-excerpt.txt has 703 characters.\n"
     ]
    }
   ],
   "source": [
    "# the code reads the contents of a specific file, prints the content, lists all text files in a \n",
    "# directory, reads each text file, and prints the filepath along with the length of the text in each file.\n",
    "def read_file(filename):\n",
    "    \"Read the contents of FILENAME and return as a string.\"\n",
    "    infile = open(filename) # windows users should use codecs.open after importing codecs\n",
    "    contents = infile.read()\n",
    "    infile.close()\n",
    "    return contents\n",
    "\n",
    "fileContent = read_file(\"/Users/yogeshgupta/Downloads/textanalysis/austen-emma-excerpt.txt\")\n",
    "print(fileContent)\n",
    "\n",
    "from os import listdir\n",
    "listdir(\"/Users/yogeshgupta/Downloads/textanalysis\")\n",
    "\n",
    "def list_textfiles(directory):\n",
    "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
    "    textfiles = []\n",
    "    for filename in listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            textfiles.append(directory + \"/\" + filename)\n",
    "    return textfiles\n",
    "\n",
    "for filepath in list_textfiles(\"/Users/yogeshgupta/Downloads/textanalysis\"):\n",
    "    text = read_file(filepath)\n",
    "    print(filepath +  \" has \" + str(len(text)) + \" characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f31736ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_of_sentence_marker(character):\n",
    "    if character == '?':\n",
    "        return True\n",
    "    elif character == '!':\n",
    "        return True\n",
    "    elif character == '.':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5206205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(end_of_sentence_marker('?') == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7e36ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(end_of_sentence_marker(\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b484de7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'P')\n",
      "(1, 'y')\n",
      "(2, 't')\n",
      "(3, 'h')\n",
      "(4, 'o')\n",
      "(5, 'n')\n"
     ]
    }
   ],
   "source": [
    "for element in enumerate('Python'):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "521b89a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for index, character in enumerate(\"Python\"):\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d59573dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The split_sentences function takes a text string as input and splits it into a list of sentences.\n",
    "def split_sentences(text):\n",
    "    #\"Split a text string into a list of sentences.\"\n",
    "    sentences = []\n",
    "    start = 0\n",
    "    for end, character in enumerate(text):\n",
    "        if end_of_sentence_marker(character):\n",
    "            sentence = text[start: end + 1]\n",
    "            sentences.append(sentence)\n",
    "            start = end + 1\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78dd370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitedSentences = split_sentences(\"This is a sentence. Should we seperate it from this one?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dac557e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'sentence']\n",
      "['should', 'we', 'seperate', 'it', 'from', 'this', 'one']\n"
     ]
    }
   ],
   "source": [
    "# the code processes each sentence from the splitedSentences list. It removes leading and trailing whitespace, removes punctuation, converts the \n",
    "# sentence to lowercase, splits it into individual words, and prints the resulting list of words for each sentence.\n",
    "for index,sent in enumerate(splitedSentences):\n",
    "    wordList = []\n",
    "    sent = sent.strip()\n",
    "    cleanText = remove_punc2(sent)\n",
    "    lowerSent = cleanText.lower()\n",
    "    wordList = lowerSent.split(' ')\n",
    "    print(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf5db0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Remove extension of a file , we can use \"os.path.splitext\" !\n",
    "# To Remove directory and gives only the file name , we can use \"os.path.basename\" !\n",
    "# Using the above two function we can get only the required file name !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cb8cab9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@Fox', '@Judie'), ('@Tristan', '@Jermain'), ('@Allyn', '@Winfred'), ('@Dennis', '@Randolph'), ('@Wallie', '@Venkat'), ('@Fo', '@Judi'), ('@Trista', '@Jermai'), ('@lyn', '@Winfre'), ('@ennis', '@Randolp'), ('@llie', '@Venka')]\n"
     ]
    }
   ],
   "source": [
    "# the code reads a file containing follower and followee names, extracts the pairs of names, \n",
    "# and stores them in a list named edges. It then prints the first 10 pairs of follower and followee names.\n",
    "\n",
    "edges = [] # In twitterName.txt we have list of names in the format as 'follower','followee'\n",
    "for line in open('/Users/yogeshgupta/Downloads/textanalysis/twitterName.txt'):\n",
    "    follower,followee = line.strip().split(';')\n",
    "    edges.append((follower,followee))\n",
    "print(edges[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8af929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@Judie', '@Judie', '@Jermain', '@Winfred', '@Randolph', '@Venkat']\n"
     ]
    }
   ],
   "source": [
    "# the code defines a function following that retrieves the list of users that a given user is following based on \n",
    "# the provided follower-followee pairs in the edges list. It then prints the list of followees for the user \"@Fox\".\n",
    "def following(user, edges):\n",
    "    \"Return a list of all users USERS is following.\"\n",
    "    followees = []\n",
    "    for follower, followee in edges:\n",
    "        if follower == user:\n",
    "            followees.append(followee)\n",
    "    return followees\n",
    "\n",
    "print(following(\"@Fox\", edges)) # The User Fox(follower) is following 6 People(Followee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b13f927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.17 µs ± 25 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit following(\"@Fox\", edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2516cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dict = {}\n",
    "for line in open(\"/Users/yogeshgupta/Downloads/textanalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    if name_a in edge_dict:\n",
    "        edge_dict[name_a].append(name_b)\n",
    "    else:\n",
    "        edge_dict[name_a] = [name_b] # We are writing to an Dictionary 'key' as Follower and 'Value as Follower'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f49bacba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@Fox': ['@Judie', '@Judie', '@Jermain', '@Winfred', '@Randolph', '@Venkat'],\n",
       " '@Tristan': ['@Jermain'],\n",
       " '@Allyn': ['@Winfred'],\n",
       " '@Dennis': ['@Randolph'],\n",
       " '@Wallie': ['@Venkat'],\n",
       " '@Fo': ['@Judi'],\n",
       " '@Trista': ['@Jermai'],\n",
       " '@lyn': ['@Winfre'],\n",
       " '@ennis': ['@Randolp', '@Raolph'],\n",
       " '@llie': ['@Venka'],\n",
       " '@ox': ['@Jud'],\n",
       " '@ristan': ['@Jerma'],\n",
       " '@llyn': ['@Winfr'],\n",
       " '@allie': ['@nkat'],\n",
       " '@Fx': ['@Jie'],\n",
       " '@Trstan': ['@rmain'],\n",
       " '@Alln': ['@nfred'],\n",
       " '@Denns': ['@ndolph'],\n",
       " '@Walli': ['@enkat']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9bfe67a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 ns ± 0.152 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def following2(user, edges):\n",
    "    return edges[user]\n",
    "\n",
    "%timeit following2(\"@Fox\", edge_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "459d674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for line in open(\"/Users/yogeshgupta/Downloads/textanalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    # repeatedly add edges to the network (1000 times)\n",
    "    for i in range(1000):\n",
    "        edges.append((name_a, name_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9fbb4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981 µs ± 7.96 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit following(\"@Fox\", edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1a6b34",
   "metadata": {},
   "source": [
    "the code reads a file containing follower and followee names, builds a dictionary edge_dict representing the social network relationships, and measures the execution time of the following2 function for the user \"@Fox\" using the edge_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a769a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.2 ns ± 1.12 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "edge_dict = {}\n",
    "for line in open(\"/Users/yogeshgupta/Downloads/textanalysis/twitterName.txt\"):\n",
    "    name_a, name_b = line.strip().split(';')\n",
    "    for i in range(1000):\n",
    "        if name_a in edge_dict:\n",
    "            edge_dict[name_a].append(name_b)\n",
    "        else:\n",
    "            edge_dict[name_a] = [name_b]\n",
    "\n",
    "%timeit following2(\"@Fox\", edge_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa62da",
   "metadata": {},
   "source": [
    "the code converts an English word to its Latin counterpart by moving the consonants encountered before the first vowel to the end of the word and adding the suffix 'ay'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3acc1c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acticePray'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# English to Latin\n",
    "# On First occurance of an vowel the loop breaks\n",
    "def translate(word):\n",
    "    \"Convert a word to latin.\"\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    start = 0\n",
    "    end = ''\n",
    "    # loop over all characters in word\n",
    "    for i, char in enumerate(word):\n",
    "        # if this character is not a vowel\n",
    "        if char not in vowels:\n",
    "            # it is a consonant, so add it to the end.\n",
    "            end += char\n",
    "        # if it is a vowel\n",
    "        else:\n",
    "            # we set the starting position to \n",
    "            # the position of this character\n",
    "            start = i\n",
    "            break\n",
    "    return word[start:] + end + 'ay'\n",
    "\n",
    "translate('Practice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "10d70e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Method 1\n",
    "# the code checks whether a given string starts with a vowel or not by comparing its first character with a predefined list of vowel characters.\n",
    "def starts_with_vowel(strings):\n",
    "    vowels = 'aeiouAEIOU'\n",
    "    if strings[0] in vowels:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "starts_with_vowel('Amazing')\n",
    "starts_with_vowel('Jack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "923a4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2\n",
    "def starts_with_vowel(word):\n",
    "    \"Return True if WORD starts with a vowel, False otherwise.\"\n",
    "    vowels = ('a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U')\n",
    "    return word.startswith(vowels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f812156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luckily'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_suffix(word,suffix):\n",
    "    word_suffix = word + suffix\n",
    "    return word_suffix\n",
    "\n",
    "add_suffix('luck','ily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6837fa9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'quickly'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'quick' \n",
    "add_suffix(word,'ly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509b5ccf",
   "metadata": {},
   "source": [
    "the code translates a word by rearranging its letters and adding a suffix based on whether the word starts with a vowel or not. The translation is achieved through recursive calls to the translate function with modified versions of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "422b0240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EEEEJkcAmazing'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def translate(word, suffix):\n",
    "    if starts_with_vowel(word):\n",
    "        return add_suffix(word, suffix)\n",
    "    return translate(word[1:] + word[0], suffix)\n",
    "\n",
    "translate('JkcEEEE','Amazing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
